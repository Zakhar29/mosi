{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5blrSkC8fgoN",
        "outputId": "3220dde6-a478-4ea3-aacb-f6d4686a84db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pymorphy3 in /usr/local/lib/python3.11/dist-packages (2.0.3)\n",
            "Requirement already satisfied: dawg2-python>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from pymorphy3) (0.9.0)\n",
            "Requirement already satisfied: pymorphy3-dicts-ru in /usr/local/lib/python3.11/dist-packages (from pymorphy3) (2.4.417150.4580142)\n"
          ]
        }
      ],
      "source": [
        "pip install pymorphy3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from collections import Counter\n",
        "import math\n",
        "import pymorphy3\n",
        "\n",
        "# Скачиваем необходимые ресурсы NLTK\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt')\n",
        "except LookupError:\n",
        "    nltk.download('punkt')\n",
        "\n",
        "try:\n",
        "    nltk.data.find('corpora/stopwords')\n",
        "except LookupError:\n",
        "    nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "morph = pymorphy3.MorphAnalyzer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1oiO8LcYfwk-",
        "outputId": "a46fbb04-672a-415d-e92c-4636a0edf390"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('russian'))\n",
        "\n"
      ],
      "metadata": {
        "id": "CPmPXJ61f5Bk"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = [\n",
        "    \"Летучие мыши увидели кошек с самыми яркими полосками, висящих вниз головой у них за ноги\",\n",
        "    \"Кошка сидит с летучими мышами на полосатом коврике под множеством гусей\"\n",
        "]"
      ],
      "metadata": {
        "id": "GRSjq0qLgddd"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(text):\n",
        "    stop_words = set(stopwords.words('russian'))\n",
        "    tokens = nltk.word_tokenize(text.lower())\n",
        "    return [morph.parse(t)[0].normal_form for t in tokens if t.isalpha() and t not in stop_words]\n",
        "\n",
        "def bag_of_words_from_processed(processed_texts):\n",
        "    all_words = []\n",
        "    for text_tokens in processed_texts:\n",
        "        all_words.extend(text_tokens)  # Добавляем токены каждого текста в общий список\n",
        "    return dict(Counter(all_words))\n",
        "\n",
        "\n",
        "def tf(text):\n",
        "  words = preprocess(text)\n",
        "  counts = Counter(words)\n",
        "  total = len(words)\n",
        "  return {word: count / total for word, count in counts.items()}\n",
        "\n",
        "def idf(texts):\n",
        "    num_docs = len(texts)\n",
        "    all_words = set()\n",
        "    for text in texts:\n",
        "      all_words.update(preprocess(text))\n",
        "\n",
        "    idfs = {}\n",
        "    for word in all_words:\n",
        "        count = sum(1 for text in texts if word in preprocess(text))\n",
        "        idfs[word] = math.log(num_docs / (count + 1))\n",
        "    return idfs\n",
        "\n",
        "def tf_idf(texts):\n",
        "  idfs = idf(texts)\n",
        "  tf_idfs = {}\n",
        "  for i, text in enumerate(texts):\n",
        "    tf_values = tf(text)\n",
        "    tf_idfs[str(i)] = {word: tf_values[word] * idfs[word] for word in tf_values}\n",
        "  return tf_idfs"
      ],
      "metadata": {
        "id": "jGQZfn4ugkJ5"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_texts = [preprocess(text) for text in texts]\n",
        "print(processed_texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PApKfautgxf_",
        "outputId": "4e3db7ff-9d05-46b8-af93-bdb1e52b4938"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['летучий', 'мышь', 'увидеть', 'кошка', 'самый', 'яркий', 'полоска', 'висеть', 'вниз', 'голова', 'нога'], ['кошка', 'сидеть', 'летучий', 'мышь', 'полосатый', 'коврик', 'множество', 'гусь']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bow = bag_of_words_from_processed(processed_texts)\n",
        "print(\"Bag of Words:\", bow)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYK-cbh1iwIW",
        "outputId": "c98bac33-71f0-4353-b54d-a5a711f123fd"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bag of Words: {'летучий': 2, 'мышь': 2, 'увидеть': 1, 'кошка': 2, 'самый': 1, 'яркий': 1, 'полоска': 1, 'висеть': 1, 'вниз': 1, 'голова': 1, 'нога': 1, 'сидеть': 1, 'полосатый': 1, 'коврик': 1, 'множество': 1, 'гусь': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_td_idf = tf_idf(bow)\n",
        "print(result_td_idf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBSnRXF1kP8O",
        "outputId": "5514ad5e-7699-4604-b4bd-0e350a450ca5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'0': {'летучий': 2.0794415416798357}, '1': {'мышь': 2.0794415416798357}, '2': {'увидеть': 2.0794415416798357}, '3': {'кошка': 2.0794415416798357}, '4': {'самый': 2.0794415416798357}, '5': {'яркий': 2.0794415416798357}, '6': {'полоска': 2.0794415416798357}, '7': {'висеть': 2.0794415416798357}, '8': {'вниз': 2.0794415416798357}, '9': {'голова': 2.0794415416798357}, '10': {'нога': 2.0794415416798357}, '11': {'сидеть': 2.0794415416798357}, '12': {'полосатый': 2.0794415416798357}, '13': {'коврик': 2.0794415416798357}, '14': {'множество': 2.0794415416798357}, '15': {'гусь': 2.0794415416798357}}\n"
          ]
        }
      ]
    }
  ]
}