{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5blrSkC8fgoN",
        "outputId": "f3fcd98d-1033-4a08-d433-d5d8abd40322"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pymorphy3 in /usr/local/lib/python3.11/dist-packages (2.0.3)\n",
            "Requirement already satisfied: dawg2-python>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from pymorphy3) (0.9.0)\n",
            "Requirement already satisfied: pymorphy3-dicts-ru in /usr/local/lib/python3.11/dist-packages (from pymorphy3) (2.4.417150.4580142)\n"
          ]
        }
      ],
      "source": [
        "pip install pymorphy3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from collections import Counter\n",
        "import math\n",
        "import pymorphy3\n",
        "\n",
        "# Скачиваем необходимые ресурсы NLTK\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "morph = pymorphy3.MorphAnalyzer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1oiO8LcYfwk-",
        "outputId": "a65a07f8-c015-4340-acba-92185f3fc7b3"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('russian'))\n",
        "\n"
      ],
      "metadata": {
        "id": "CPmPXJ61f5Bk"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = [\n",
        "    \"Летучие мыши увидели кошек с самыми яркими полосками, висящих вниз головой у них за ноги\",\n",
        "    \"Кошка сидит с летучими мышами на полосатом коврике под множеством гусей\"\n",
        "]"
      ],
      "metadata": {
        "id": "GRSjq0qLgddd"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(text):\n",
        "    stop_words = set(stopwords.words('russian'))\n",
        "    tokens = nltk.word_tokenize(text.lower())\n",
        "    return [morph.parse(t)[0].normal_form for t in tokens if t.isalpha() and t not in stop_words]\n",
        "\n",
        "def bag_of_words_from_processed(processed_texts):\n",
        "    all_words = []\n",
        "    for text_tokens in processed_texts:\n",
        "        all_words.extend(text_tokens)  # Добавляем токены каждого текста в общий список\n",
        "    return dict(Counter(all_words))\n",
        "\n",
        "\n",
        "\n",
        "def tf(text):\n",
        "    term_count = Counter(text)\n",
        "    total_terms = len(text)\n",
        "    return {word: count / total_terms for word, count in term_count.items()}\n",
        "\n",
        "def idf(texts):\n",
        "    num_docs = len(texts)\n",
        "    idf_values = {}  # Переименовал idf в idf_values, чтобы не путать с именем функции\n",
        "    all_words = set(word for text in texts for word in text)\n",
        "\n",
        "    for word in all_words:\n",
        "        containing_docs = sum(1 for text in texts if word in text)\n",
        "        idf_values[word] = math.log(num_docs / (1 + containing_docs)) + 1\n",
        "\n",
        "    return idf_values\n",
        "\n",
        "def tf_idf(texts):\n",
        "    idf_values = idf(texts)  # Вызываем idf с правильным аргументом\n",
        "    tf_idf_values = []\n",
        "\n",
        "    for text in texts:\n",
        "        tf_values = tf(text) # Вызываем tf c аргументом text\n",
        "        tf_idf = {word: tf_values[word] * idf_values[word] for word in tf_values}\n",
        "        tf_idf_values.append(tf_idf)\n",
        "\n",
        "    return tf_idf_values"
      ],
      "metadata": {
        "id": "jGQZfn4ugkJ5"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_texts = [preprocess(text) for text in texts]\n",
        "print(processed_texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PApKfautgxf_",
        "outputId": "138c2b64-4244-4813-babb-5571b0081c90"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['летучий', 'мышь', 'увидеть', 'кошка', 'самый', 'яркий', 'полоска', 'висеть', 'вниз', 'голова', 'нога'], ['кошка', 'сидеть', 'летучий', 'мышь', 'полосатый', 'коврик', 'множество', 'гусь']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bow = bag_of_words_from_processed(processed_texts)\n",
        "print(\"Bag of Words:\", bow)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYK-cbh1iwIW",
        "outputId": "239529dd-434e-4f6b-d4b1-a48b06220740"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bag of Words: {'летучий': 2, 'мышь': 2, 'увидеть': 1, 'кошка': 2, 'самый': 1, 'яркий': 1, 'полоска': 1, 'висеть': 1, 'вниз': 1, 'голова': 1, 'нога': 1, 'сидеть': 1, 'полосатый': 1, 'коврик': 1, 'множество': 1, 'гусь': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_td_idf = tf_idf(processed_texts)\n",
        "print(result_td_idf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBSnRXF1kP8O",
        "outputId": "e0350e6a-a253-4112-fc01-87bf0ef631c0"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'летучий': 0.05404862653562142, 'мышь': 0.05404862653562142, 'увидеть': 0.09090909090909091, 'кошка': 0.05404862653562142, 'самый': 0.09090909090909091, 'яркий': 0.09090909090909091, 'полоска': 0.09090909090909091, 'висеть': 0.09090909090909091, 'вниз': 0.09090909090909091, 'голова': 0.09090909090909091, 'нога': 0.09090909090909091}, {'кошка': 0.07431686148647945, 'сидеть': 0.125, 'летучий': 0.07431686148647945, 'мышь': 0.07431686148647945, 'полосатый': 0.125, 'коврик': 0.125, 'множество': 0.125, 'гусь': 0.125}]\n"
          ]
        }
      ]
    }
  ]
}