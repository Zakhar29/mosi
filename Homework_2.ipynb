{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5blrSkC8fgoN",
        "outputId": "b7982f32-8b53-48e8-863e-dff35d185d77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymorphy3\n",
            "  Downloading pymorphy3-2.0.3-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting dawg2-python>=0.8.0 (from pymorphy3)\n",
            "  Downloading dawg2_python-0.9.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting pymorphy3-dicts-ru (from pymorphy3)\n",
            "  Downloading pymorphy3_dicts_ru-2.4.417150.4580142-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Downloading pymorphy3-2.0.3-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.8/53.8 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dawg2_python-0.9.0-py3-none-any.whl (9.3 kB)\n",
            "Downloading pymorphy3_dicts_ru-2.4.417150.4580142-py2.py3-none-any.whl (8.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pymorphy3-dicts-ru, dawg2-python, pymorphy3\n",
            "Successfully installed dawg2-python-0.9.0 pymorphy3-2.0.3 pymorphy3-dicts-ru-2.4.417150.4580142\n"
          ]
        }
      ],
      "source": [
        "pip install pymorphy3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from collections import Counter\n",
        "import math\n",
        "import pymorphy3\n",
        "\n",
        "# Скачиваем необходимые ресурсы NLTK\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "morph = pymorphy3.MorphAnalyzer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1oiO8LcYfwk-",
        "outputId": "4bfb6915-288a-424f-99d2-65820449e23c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('russian'))\n",
        "\n"
      ],
      "metadata": {
        "id": "CPmPXJ61f5Bk"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = [\n",
        "    \"Летучие мыши увидели кошек с самыми яркими полосками, висящих вниз головой у них за ноги\",\n",
        "    \"Кошка сидит с летучими мышами на полосатом коврике под множеством гусей\"\n",
        "]"
      ],
      "metadata": {
        "id": "GRSjq0qLgddd"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(text):\n",
        "    stop_words = set(stopwords.words('russian'))\n",
        "    tokens = nltk.word_tokenize(text.lower())\n",
        "    return [morph.parse(t)[0].normal_form for t in tokens if t.isalpha() and t not in stop_words]\n",
        "\n",
        "def bag_of_words_from_processed(processed_texts):\n",
        "    all_words = []\n",
        "    for text_tokens in processed_texts:\n",
        "        all_words.extend(text_tokens)  # Добавляем токены каждого текста в общий список\n",
        "    return dict(Counter(all_words))\n",
        "\n",
        "\n",
        "def tf(text):\n",
        "  words = preprocess(text)\n",
        "  counts = Counter(words)\n",
        "  total = len(words)\n",
        "  return {word: count / total for word, count in counts.items()}\n",
        "\n",
        "def idf(texts):\n",
        "    num_docs = len(texts)\n",
        "    all_words = set()\n",
        "    for text in texts:\n",
        "      all_words.update(preprocess(text))\n",
        "\n",
        "    idfs = {}\n",
        "    for word in all_words:\n",
        "        count = sum(1 for text in texts if word in preprocess(text))\n",
        "        idfs[word] = math.log(num_docs / (count + 1))\n",
        "    return idfs\n",
        "\n",
        "def tf_idf(texts):\n",
        "  idfs = idf(texts)\n",
        "  tf_idfs = {}\n",
        "  for i, text in enumerate(texts):\n",
        "    tf_values = tf(text)\n",
        "    tf_idfs[str(i)] = {word: tf_values[word] * idfs[word] for word in tf_values}\n",
        "  return tf_idfs"
      ],
      "metadata": {
        "id": "jGQZfn4ugkJ5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_texts = [preprocess(text) for text in texts]\n",
        "print(processed_texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PApKfautgxf_",
        "outputId": "b6c596c6-d084-4c59-f310-9767c411085a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['летучий', 'мышь', 'увидеть', 'кошка', 'самый', 'яркий', 'полоска', 'висеть', 'вниз', 'голова', 'нога'], ['кошка', 'сидеть', 'летучий', 'мышь', 'полосатый', 'коврик', 'множество', 'гусь']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bow = bag_of_words_from_processed(processed_texts)\n",
        "print(\"Bag of Words:\", bow)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYK-cbh1iwIW",
        "outputId": "8c432415-8c9e-43ea-df9c-1ad2d385e3fb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bag of Words: {'летучий': 2, 'мышь': 2, 'увидеть': 1, 'кошка': 2, 'самый': 1, 'яркий': 1, 'полоска': 1, 'висеть': 1, 'вниз': 1, 'голова': 1, 'нога': 1, 'сидеть': 1, 'полосатый': 1, 'коврик': 1, 'множество': 1, 'гусь': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_td_idf = tf_idf(bow)\n",
        "print(result_td_idf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBSnRXF1kP8O",
        "outputId": "6d2326e2-c2a1-44d6-aa5d-0278ab6f7066"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'0': {'летучий': 2.0794415416798357}, '1': {'мышь': 2.0794415416798357}, '2': {'увидеть': 2.0794415416798357}, '3': {'кошка': 2.0794415416798357}, '4': {'самый': 2.0794415416798357}, '5': {'яркий': 2.0794415416798357}, '6': {'полоска': 2.0794415416798357}, '7': {'висеть': 2.0794415416798357}, '8': {'вниз': 2.0794415416798357}, '9': {'голова': 2.0794415416798357}, '10': {'нога': 2.0794415416798357}, '11': {'сидеть': 2.0794415416798357}, '12': {'полосатый': 2.0794415416798357}, '13': {'коврик': 2.0794415416798357}, '14': {'множество': 2.0794415416798357}, '15': {'гусь': 2.0794415416798357}}\n"
          ]
        }
      ]
    }
  ]
}